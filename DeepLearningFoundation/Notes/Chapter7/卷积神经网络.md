## Chapter7: 卷积神经网络（Convolutional Neural Network，CNN）
### 一，整体结构
* CNN中新出现了卷积层（Convolution层）和池化层（Pooling层）。
* 相邻层的所有神经元之间都有连接，这称为全连接（fully-connected）。
* 全连接的神经网络中，Affine层后面跟着激活函数ReLU层（或者Sigmoid层）。
* 这可以理解为之前的“Affine-ReLU”连接被替换成了“Convolution-ReLU-(Pooling)”连接。

### 二，卷积层
#### （一）全连接层存在什么问题
1. 那就是数据的形状被“忽视”了。比如，输入数据是图像时，图像通常是高、长、通道方向上的3维形状。但是，向全连接层输入时，需要将3维数据拉平为1维数据。
2. 图像是3维形状，这个形状中应该含有重要的空间信息。比如，空间上邻近的像素为相似的值、RBG的各个通道之间分别有密切的关联性、相距较远的像素之间没有什么关联等，3维形状中可能隐藏有值得提取的本质模式。但是，因为全连接层会忽视形状，将全部的输入数据作为相同的神经元（同一维度的神经元）处理，所以无法利用与形状相关的信息。
#### （二）卷积层优势
1. 卷积层可以保持形状不变。当输入数据是图像时，卷积层会以3维数据的形式接收输入数据，并同样以3维数据的形式输出至下一层。因此，在CNN中，可以（有可能）正确理解图像等具有形状的数据。
2. CNN 中，有时将卷积层的输入输出数据称为特征图（feature map）。其中，卷积层的输入数据称为输入特征图（input feature map），输出数据称为输出特征图（output feature map）。
##### 1. 卷积运算:
* 卷积层进行的处理就是卷积运算。卷积运算相当于图像处理中的“滤波器运算”。
* 